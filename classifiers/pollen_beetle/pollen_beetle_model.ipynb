{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** FP-modules version 2.7.9 ***\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/frth/notebooks')\n",
    "\n",
    "import fpmodules as fp\n",
    "import fpmodules.tools as fk\n",
    "\n",
    "feature_id = list(fk.get_feature_ids().values())\n",
    "#from helpers import * \n",
    "import sys\n",
    "from fplearn.processing import  mlready_data, compile_process_segmented_data\n",
    "from fplearn.run import run_model, evaluate_model\n",
    "from fplearn.tsne import TSNEplot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.get_peripheral(name=61,per_id=46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation session 1014\n",
    "\n",
    "def empty_dict(session_id=0):\n",
    "    dict = {\n",
    "        'session': session_id,\n",
    "        'meas_id': [],\n",
    "        'file_list': [],\n",
    "        'path': '',\n",
    "        'peri': [],\n",
    "        'feat': [],\n",
    "        'insects': []\n",
    "    }\n",
    "    return dict\n",
    "\n",
    "species = {\n",
    "    'Pollen_beetle/Danes': empty_dict(session_id=816),\n",
    "    'Pollen_beetle/Swiss': empty_dict(session_id=777),\n",
    "    'Drosophilidae/Swiss': empty_dict(session_id=794),\n",
    "    'Honeybee': empty_dict(session_id=805),\n",
    "    'Greenhouse rove beetle': empty_dict(session_id=409),\n",
    "    'Cabbage steam weevil': empty_dict(session_id=773),\n",
    "    'Mealy cabbage aphid': empty_dict(session_id=962),\n",
    "    'Aphis gossipii': empty_dict(988),\n",
    "    'Lygocoris pabulinus': empty_dict(1118),\n",
    "    'Aphis fabae': empty_dict(513),\n",
    "    'Cabbage seed weevil': empty_dict(873),\n",
    "    'Codling moth': empty_dict(588),\n",
    "    'Pod midge': empty_dict(985),\n",
    "    'Bumblebee': empty_dict(462),\n",
    "    'Parasitic wasp': empty_dict(750),\n",
    "    'Green lacewing': empty_dict(646),\n",
    "    'Tersilochus heterocerus': empty_dict(879),\n",
    "    'House fly': empty_dict(469),\n",
    "    'Common green bottle fly': empty_dict(452),\n",
    "    'Aphid gall midge': empty_dict(567),\n",
    "    'Migrant hoverfly': empty_dict(478)\n",
    "}\n",
    "labels = list(species.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for l in labels:\n",
    "        session_id = str(species[l]['session'])\n",
    "        print(session_id)\n",
    "\n",
    "        insect = fk.pickle_wrapper(fp.get_insects, '/home/' + user + '/data/features/pollen_beetles/session/' + session_id, 'insects.pkl', sessionid=session_id, all_segments=True)\n",
    "        if (len(insect)) > 2000:\n",
    "            insect = insect[0:2000]\n",
    "        #feat = fk.pickle_wrapper(fp.get_features, '/home/' + user + '/data/features/pollen_beetles/session/' + session_id, 'features.pkl', featureid=feat_id, sessionid=session_id, cache_path=cache + session_id)\n",
    "        #feat = feat[feat['WavelengthId']=='810']\n",
    "\n",
    "        #insect_ids = feat['MeasurementId'].isin(insect['MeasurementId']) &  feat['SegmentId'].isin(insect['SegmentId'])\n",
    "        #feat = feat[insect_ids]\n",
    "\n",
    "        #insect = pd.merge(insect, feat, on=['MeasurementId','SegmentId','SessionId', 'Datetime']).sort_values('Datetime')\n",
    "\n",
    "        meas_id = insect['MeasurementId'].tolist() #insect.groupby('MeasurementId').sum().index.tolist()\n",
    "        file_list = fk.calc_filename_from_id(meas_id)\n",
    "\n",
    "        species[l]['meas_id'] = meas_id\n",
    "        species[l]['file_list'] = file_list.tolist()\n",
    "        #species[l]['feat'] = feat\n",
    "        species[l]['insects'] = insect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for l in labels:\n",
    "#    path='/home/' + user + '/EventCache/Events/' + str(species[l]['session'])\n",
    "#    fp.download_events(id_list=species[l]['meas_id'],multi=True, path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "[species[s]['session'] for s in species]\n",
    "session_groups = [816,777]#[[816, 777, 1014],  794, 805, 409, 773, 962, 988, 1118, 513, 873, 588, 985, 462, 750, 646, 879, 469, 452, 567, 478]\n",
    "maxlist = [10,10]#[[100, 100, 100]] + [100]*19\n",
    "startdateid = [20210101, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for s in species:\n",
    "#    print(len(fp.get_insects(sessionid=species[s]['session'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'startdateid': 20210101, 'enddateid': None, 'starttimeid': None, 'endtimeid': None}\n",
      "Some files exist, not downloading again.\n",
      "100% complete      [==================================================]\n",
      "\n",
      "{'startdateid': None, 'enddateid': None, 'starttimeid': None, 'endtimeid': None}\n",
      "Some files exist, not downloading again.\n",
      "100% complete      [==================================================]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data, labels, files, raw, mid, seg, wave = \\\n",
    "    compile_process_segmented_data(session_groups, '/home/frth/EventCache/Events', \n",
    "                                   maxlist, split_channels=True, data_length=1000, verbose=0, startdateid=startdateid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [169918, 20, 40, 20, 40, 40, 20]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5fd84dce9f9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m (Xt, Xv, Xe, Yt, Yv, Ye, \\\n\u001b[1;32m      3\u001b[0m  ft, fv, fe, rt, rv, re, mt, mv, me, st, sv, se, wt, wv, we), cw = \\\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmlready_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mXv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/fplearn/processing.py\u001b[0m in \u001b[0;36mmlready_data\u001b[0;34m(X, Y, random_state, *datasets)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0mclass_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_class_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0mY_1hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m     split_datasets = multi_split(X, Y_1hot, *datasets,\n\u001b[0m\u001b[1;32m    480\u001b[0m                                  random_state=random_state)\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/fplearn/processing.py\u001b[0m in \u001b[0;36mmulti_split\u001b[0;34m(ratios, *datasets, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratios\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mratios\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratios\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mratios\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0msplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratios\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2170\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2172\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2174\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \"\"\"\n\u001b[1;32m    298\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [169918, 20, 40, 20, 40, 40, 20]"
     ]
    }
   ],
   "source": [
    "data_length = 1000\n",
    "(Xt, Xv, Xe, Yt, Yv, Ye, \\\n",
    " ft, fv, fe, rt, rv, re, mt, mv, me, st, sv, se, wt, wv, we), cw = \\\n",
    "    mlready_data(data, labels, files, raw, mid, seg, wave)\n",
    "Xt = Xt.reshape([-1, data_length, 1])\n",
    "Xv = Xv.reshape([-1, data_length, 1])\n",
    "Xe = Xe.reshape([-1, data_length, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes_short = ['Pollen_beetle', 'Drosophilidae', 'Honeybee', 'Greenhouse rove beetle', 'Cabbage steam weevil'] # list(species.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params = run_model(Xt, Xv, Yt, Yv, class_weights=cw,\n",
    "                          batch_size=200, epochs=300, stop_patience=10, learning_rate=0.0005)\n",
    "model.save('/home/frth/notebooks/syngenta/model/multi_class_1000_w_1014_2')\n",
    "\n",
    "#model = keras.models.load_model('/home/frth/notebooks/syngenta/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_short = ['Pollen beetles'] + list(species.keys())[2:]\n",
    "plt.figure(figsize=(15,15))\n",
    "evals = evaluate_model(model, model.history.history, Xe.astype(float), Ye, classes_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.update({\"sessions\": str(session_groups),\n",
    "               \"test_accuracy\": evals[-1][-1]})\n",
    "params.pop('callbacks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fplearn.tsne import TSNEplot\n",
    "oom = 1000\n",
    "plt.figure(figsize=(12,8))\n",
    "tsne = TSNEplot(Xt[:oom], Yt[:oom], model, classes=classes_short)\n",
    "tsne.fit()\n",
    "tsne.plot()\n",
    "plt.gca().set_xlabel('test')\n",
    "plt.gcf().set_size_inches(18.5, 10.5)\n",
    "tsne_fig = plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4082b4c0ff6287cfc869426458e61daf0f96e72318d7dae093de8e29c11fa2fe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('fp_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
